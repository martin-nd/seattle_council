---
title: "Investigating the Tendencies of the Seattle City Council"
author: "Martin Sloley"
output:
    bookdown::html_document2:
        toc: true
        theme: united
---

```{r setup, include=F}
knitr::opts_chunk$set(echo = F)
library(tidyverse)
library(plotly)
library(caret)
library(reshape2)
data = read_csv("scaled_clean_tendency_data.csv")
normdat = read_csv("norm_scaled_clean_tendency_data.csv")
```

```{python setup2, includ=F}
from statsmodels.multivariate.manova import MANOVA
import polars as pl
import pandas as pd
from polars import col as c
import re
import numpy as np
from matplotlib import pyplot as plt
import seaborn as sns
data = pl.read_csv("scaled_clean_tendency_data.csv")
newcols = ["_".join(re.split("[- ]", colname)) for colname in data.columns]
data.columns = newcols
normdat = pl.read_csv("norm_scaled_clean_tendency_data.csv")
normdat.columns = newcols
```

# Overview

## Goals

One problem with public policy (for me, as an extremely lazy person) is the amount of reading required to get an overview of what matters to local political figures. In order to get a better idea of what the Seattle City Council members consider important, I figured that I could just see what they seem to talk about often, with the goal being putting together a good idea of what matters to each council member and having a dataset that I can draw some conclusions from regarding how I may want to vote in the future.

## Data collection

In order to get a good idea of what council members find important, I figured it best to go straight to the source. Seattle local government offers a [news RSS feed](https://news.seattle.gov) that is freely accessible. I used python's `feedparser` library to grab all RSS feed entries from the last 10 years and stored them in a local Mongo database. Each RSS entry comes with a date, a link to the article or post, and some other metadata. I then sifted through the 20248 entries as of May 15, 2024 and identified every feed entry with a link to `council.seattle.gov`.

Using python's `BeautifulSoup` library, I was able to scrape the raw text of each of these council announcements and put those into a separate collection in the same Mongo database. Then, using regex, I extracted the council member whose office published the announcement for each announcement. After finding all this, I used `nltk` to remove stopwords and create frequency distributions for word count to get a sense of the subjects of announcements. Using this frequency distributions I came up with the following categories for each announcement:

- Budget
- Traffic
- Public transit
- Utilities-light
- Utilities-heat
- Utilities-water
- Utilities-electric
- Civil unrest
- Civil rights
- Parks
- Labor
- Housing
- Homelessness
- Political-legislation
- Political-city council
- Political-mayor
- Political-general
- Crime
- Police-general
- Police-controversy
- Police-political
- Public safety
- Public health
- Public services
- Covid-general
- Covid-vaccines
- Covid-masks
- Infrastructure
- Business
- Real estate
- Welfare-unemployment
- Welfare-food
- Economics
- Environmental
- Sports

After determining these categories, I proceeded to use a zero-shot, deep-learning text classification model to measure the strength of the relationship between these categories and each announcement. I used an open source model and ran it locally. The specific model is available [here](https://huggingface.co/BAAI/bge-reranker-v2-m3). I used normalized outputs and measured the strength of the relationship for all categories for each announcement. I then transformed these measurements to better adhere to Gaussian distributions using the transformation: $\mathcal{G} = \frac{1}{2}\log{\left(\frac{p}{1-p}\right)}$. After transforming I centered and scaled it to get data that looks like this:

```{r display data, echo=F, message=F, warning=F}
DT::datatable(
  data %>% select(-date),
  extensions = c('FixedColumns', "Buttons"),
  options = list(
    scrollX = TRUE,
    scrollY = TRUE,
    fixedColumns = list(leftColumns = 2)
  )
)
```

All code used is available in the [github repo](https://github.com/martin-nd/seattle_council), although, be warned, the collection and processing is extremely messy. If this wasn't just a one-time scrape I would have been cleaner.

# A note on the use of deep learning

As many who know me will attest, I am the first to dismiss the capabilities of deep learning as more hype than substance. I still hold this position (at least until the public's expectations of deep learning capabilities align with their true capabilities), and my use of deep learning here will not go unconsidered. Something to keep in mind throughout this whole investigation from this point forward, is that all these data points were generated by the model's embedding of the tokens that make up the category, and the tokens that make up the article. The model has no actual semantic knowledge of the world, and we will address that; both in how that rears its head in the data, and how that may affect our conclusions.

Before we go any further, let me show you an example. You may have noticed that some of the subjects I looked for were covid-related, but I have data from 2014-2024. Let's see how the model characterized announcements from pre-covid.

```{r covid relevancy graph, fig.width = 10, fig.height = 8}
ggplot(data, aes(x = date, y = `covid-general`, color = councilmember)) +
        geom_point(size = 0.9, alpha = 0.7) +
        labs(title = "Covid Related Announcement Prevalency Over Time",
             y = "Prevalence Score", x = "Date", color = "Council Member") +
        theme(legend.text = element_text(size = 8),
              legend.title = element_text(size = 10))
```

As you can see, there's a legitimate argument that anything under 1 is just random noise. We can combat this by setting anything under 1 to 0, and subtracting 1 from the remaining values. That way there's a minimum value that we can consider as meaning that the subject of the announcement and the subject tested are orthogonal. Unless otherwise stated, assume the use of this sparse dataset moving forward:

```{r}
DT::datatable(
  normdat %>% select(-date),
  extensions = c('FixedColumns', "Buttons"),
  options = list(
    scrollX = TRUE,
    scrollY = TRUE,
    fixedColumns = list(leftColumns = 2)
  )
)
```

# Initial observations

The first step we should take is making sure that the council members are actually talking about different things. We can do this using a MANOVA test.

```{python manova test}
formula_exog = " + ".join(normdat.drop(["councilmember", "date"]).columns)
mv_test = MANOVA.from_formula(f"councilmember ~ {formula_exog}", normdat.drop("date").to_pandas())
test = mv_test.mv_test().results
results_table = {
    "subject": list(test.keys())[1:],
    "pval": []
}
for var in results_table["subject"]:
    pval = test[var]["stat"].iloc[2, 4]
    results_table["pval"].append(pval)

pd.DataFrame(results_table).sort_values(by = "pval", ascending = False).reset_index(drop = True)
```

It would appear that the members of the city council are not always talking about the same things. I would say that's good, it means there's a diversity of thought within the council. Let's get some aggregates and see what each council member is talking about. We can do this with a parallel coordinates plot.

```{r, warning=F, message=F, fig.width=10, fig.height=8}
norm_melted = normdat %>%
        select(-date) %>%
        group_by(councilmember) %>%
        summarize_if(is.numeric, mean) %>%
        melt()

ggplot(norm_melted, aes(x = variable, y = value, color = councilmember, group = councilmember)) +
        geom_line() +
        labs(title = "Parallel Coordinates Plot of Subject Prevalence per Council Member",
             y = "Prevalence Score", x = "Subject", color = "Council Member") +
        theme(axis.text.x = element_text(size = 9, angle = 45))
```


We can also compare subsets, for example, the three most prevalent council members in the data set.

```{r top3, message=F, warning=F, fig.width = 10, fig.height = 8}
top3 = normdat %>%
        group_by(councilmember) %>%
        summarize(count = n()) %>%
        arrange(desc(count)) %>%
        head(3) %>%
        .$councilmember

top3_melt = norm_melted %>%
        filter(councilmember %in% top3)

ggplot(top3_melt, aes(x = variable, y = value, color = councilmember, group = councilmember)) +
  geom_line() +
  labs(title = "Parallel Coordinates Plot of Subject Prevalence for 3 Most Prolific Council Members",
       y = "Prevalence Score", x = "Subject", color = "Council Member") +
  theme(axis.text.x = element_text(size = 9, angle = 45))
```

We can see here that council members Herbold and Sawant tend not to talk about the same subjects.

# Unsupervised learning